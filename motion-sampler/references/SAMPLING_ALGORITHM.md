# Frame Sampling Algorithm

## Overview

The motion sampler uses a fixed-interval temporal sampling strategy to extract representative frames from dashcam videos while avoiding common video artifacts.

## Core Algorithm

### Input Parameters
- `video_path`: Path to MP4 video file
- `sample_interval`: Seconds between frames (default: 10.0)
- `start_offset`: Seconds to skip at beginning (default: 1.0)
- `end_offset`: Seconds to avoid at end (default: 1.0)

### Sampling Strategy

```python
def calculate_sample_timestamps(duration_s: float, interval: float = 10.0) -> List[float]:
    """
    Calculate timestamps to sample from video

    Args:
        duration_s: Total video duration in seconds
        interval: Seconds between samples

    Returns:
        List of timestamps (in seconds) to extract
    """
    start_offset = 1.0  # Avoid black frames at start
    end_offset = 1.0    # Avoid fade-out at end

    usable_duration = duration_s - start_offset - end_offset

    if usable_duration < 3:
        # Very short video: just get middle frame
        return [duration_s / 2]

    timestamps = []
    current_time = start_offset

    # Sample at regular intervals
    while current_time < (duration_s - end_offset):
        timestamps.append(current_time)
        current_time += interval

    # Always include the end frame
    timestamps.append(duration_s - end_offset)

    return timestamps
```

### Example: 60-second video, 10-second interval

```
Video timeline: [0s ────────────────────────────────── 60s]
Usable range:      [1s ────────────────────────── 59s]

Sample points:
F001: 1.0s   (START)
F002: 11.0s  (interval #1)
F003: 21.0s  (interval #2)
F004: 31.0s  (interval #3)
F005: 41.0s  (interval #4)
F006: 51.0s  (interval #5)
F007: 59.0s  (END - always included)

Total frames: 7
```

## Edge Cases

### Very Short Videos (< 3 seconds)
```python
if usable_duration < 3:
    return [duration_s / 2]  # Single middle frame
```

**Example:**
- 5s video → Single frame at 2.5s
- 2s video → Skipped (below min_duration threshold)

### Videos Just Over Threshold
```python
# 8-second video, 10s interval
duration = 8.0
usable = 8.0 - 1.0 - 1.0 = 6.0 seconds

Samples:
- 1.0s (START)
- 7.0s (END)
Result: 2 frames
```

### Long Videos
```python
# 180-second video (3 minutes), 10s interval
duration = 180.0

Samples:
1s, 11s, 21s, 31s, 41s, 51s, 61s, 71s, 81s, 91s,
101s, 111s, 121s, 131s, 141s, 151s, 161s, 171s, 179s

Result: 19 frames
```

## Why This Approach?

### 1. Avoid Black Frames
- **Problem:** Many dashcam videos start with 0.5-1.0s of black/static frames
- **Solution:** Start sampling at 1.0s

### 2. Avoid Fade-Out
- **Problem:** Some videos have fade-to-black in last 0.5-1.0s
- **Solution:** End sampling 1.0s before video end

### 3. Always Include End Frame
- **Rationale:** Captures final location/scene
- **Implementation:** Last timestamp = duration - 1.0s

### 4. Regular Intervals
- **Benefit:** Predictable, easy to understand
- **Use case:** "Show me every 10 seconds of my drive"
- **Alternative considered:** Adaptive sampling based on motion (future enhancement)

## Frame Extraction Process

### 1. Open Video
```python
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)  # Usually 24 or 30 fps
total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)
duration_s = total_frames / fps
```

### 2. Calculate Frame Numbers
```python
for timestamp_s in sample_timestamps:
    frame_number = int(timestamp_s * fps)

    # Seek to frame
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)

    # Read frame
    ret, frame = cap.read()
```

### 3. Save as JPEG
```python
output_path = f"{video_stem}_F{position:03d}_{timestamp_ms:06d}ms.jpg"
cv2.imwrite(output_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 92])
```

## Performance Characteristics

### Time Complexity
- **Per video:** O(n) where n = number of samples
- **Total:** O(V × n) where V = number of videos
- **Typical:** 7 samples × 2,000 videos = 14,000 frame extractions

### Space Complexity
- **Memory:** O(1) per frame (frames not accumulated)
- **Disk:** O(V × n × frame_size)
- **Typical:** 2,000 videos × 7 frames × 1.7MB = ~24 GB

### CPU Utilization
- **Single-threaded:** 20-30% (I/O bound)
- **Multi-threaded (4 workers):** 70-90% (compute bound)
- **Bottleneck:** Video decoding (CPU) → JPEG encoding (CPU)

## Future Optimizations

### GPU Acceleration (v2.0)
```python
# NVDEC hardware video decoding
cap = cv2.VideoCapture(video_path, cv2.CAP_FFMPEG, [
    cv2.CAP_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY
])
```
**Expected speedup:** 3-5x

### Smart Sampling (v3.0)
```python
# Skip static scenes (parked car)
# Dense sample during motion
# Detect scene changes
```
**Benefit:** Reduce frames while increasing information density

### Adaptive Quality (v2.5)
```python
# Higher quality for important scenes
# Lower quality for repetitive highway driving
```
**Benefit:** Balance quality and storage

## Validation

### Test Cases

**Test 1: Standard 60s video**
- Input: 60s video, 10s interval
- Expected: 7 frames (1s, 11s, 21s, 31s, 41s, 51s, 59s)
- Actual: ✓ Pass

**Test 2: Short 5s video**
- Input: 5s video, 10s interval
- Expected: 2 frames (1s, 4s)
- Actual: ✓ Pass

**Test 3: Very short 2s video**
- Input: 2s video (below min_duration=3s)
- Expected: Skipped
- Actual: ✓ Pass

**Test 4: Dense sampling**
- Input: 30s video, 5s interval
- Expected: 7 frames (1s, 6s, 11s, 16s, 21s, 26s, 29s)
- Actual: ✓ Pass

**Test 5: Sparse sampling**
- Input: 60s video, 30s interval
- Expected: 3 frames (1s, 31s, 59s)
- Actual: ✓ Pass
